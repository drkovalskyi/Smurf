Due to the fast evolution of the LHC machine, with a rapid rise in the
instantaneous luminosity, the data taking conditions have changed
rapidly.  In particular it is difficult to exactly reproduce the
number of overlapping events (i.e. pile-up) between data and
simulation, and thus there will be differences in the number of
reconstructed primary vertices. We correct this disagreement by
reweighting the simulation to match the number of pileup events in data. 

The target pileup distribution for data is generated using the instantaneous luminosity 
per bunch crossing for each luminosity section, stored in the LumiDB database, 
and the total pp inelastic cross section of $69.4$mb, integrated over the 
full data-taking period. 
%A poissonian smearing is applied to model
%statistical fluctuations in the actual number of pileup events 
%present in the data. 
The source distribution is taken from the PileupInfo
collection which stores the true number of pileup events mixed with the 
particular hard interaction process in each Monte Carlo event. 

%Comparisons of the pileup distribution from the Summer12 Monte Carlo samples and the pileup 
%distribution in data is shown in Figure \ref{fig:NPU}. 
%The resulting weighting factors are shown in Figure 
%\ref{fig:PUReweightingFactors}. 

%\begin{figure}[hbt]
%\begin{center}
%\subfigure[Number of pile-up interactions]{\label{fig:NPU}
%\includegraphics[width=.4\textwidth]{figures/NPUDistributions.pdf}}
%\subfigure[Rewighting factors]{\label{fig:PUReweightingFactors}
%\includegraphics[width=.4\textwidth]{figures/ReweightingFactors.pdf}}
%\caption{\label{fig:PU} Number of pile-up interactions in data and in the Summer12 MC samples and corresponding event weights.}
%\end{center}
%\end{figure}

Figure~\ref{fig:PUValidation_Full2012} shows the 
the number of reconstructed primary vertices from \dyll\ events in 
data and Monte Carlo after this reweighting procedure. 
The residual differences reflect the size of the systematic uncertainty in the determination 
of the amount of pileup present in the data. Since the dependence 
of the efficiencies for selecting signal and background events on 
pileup are small, this systematic uncertainty due to the pileup 
is small when propagated to the final 
result.

\begin{figure}[hbt]
\begin{center}
\includegraphics[width=0.45\linewidth]{figures/nvtx.pdf}
\caption{\label{fig:PUValidation_Full2012}Number of reconstructed primary vertices for data and Monte Carlo reweighted in the number 
of pileup events for the 2012 dataset.}
\end{center}
\end{figure}

